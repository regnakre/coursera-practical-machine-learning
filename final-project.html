<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta name="generator" content="pandoc" />

<title>Exercise manner prediction</title>

<!-- Latest compiled and minified CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

<!-- Optional theme -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap-theme.min.css" integrity="sha384-fLW2N01lMqjakBkx3l/M9EahuwpSfeNvV63J5ezn3uZzapT0u7EYsXMjQV+0En5r" crossorigin="anonymous">

<!-- Latest compiled and minified JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>

</head>
<body>
 <h1 class="text-center">Practical Machine Learning - Final Project</h1>
 <div class="text-center">By Erkan Er</div>
 <hr/>
 <h2>Data Preparation and Exploration</h2>
 <p>First, let's install/include the required libraries</p>

<pre><code>library(lattice); library(ggplot2); library(caret); library(randomForest); 
library(rpart); library(rpart.plot);library(RColorBrewer);library(rattle)
</code></pre>

<p>Then, let's read the training and testing data.</p>

<pre><code>training &lt;- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
testing &lt;- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))

# Show the colums with NA count
data.frame(colSums(is.na(training)))
</code></pre>

<p>Clean the NA rows:</p>

<pre><code># remove the columns that contains only NA values
training &lt;- training[, colSums(is.na(training)) == 0]
testing &lt;- testing[, colSums(is.na(testing)) == 0]
</code></pre>

<p>Delete the variables that are irrelevant: user_name, raw_timestamp_part_1, raw_timestamp_part_,2 cvtd_timestamp, new_window, and  num_window (columns 1 to 7). </p>

<pre><code>training   &lt;- training[,-c(1:7)]
testing &lt;- testing[,-c(1:7)]
</code></pre>

<p>Partition the data so that 70% of the training dataset into training and the remaining 30% to testing</p>

<pre><code>intrain &lt;- createDataPartition(y = training$classe, p = 0.7, list=FALSE)
training_train &lt;- training[intrain,]
training_test &lt;- training[-intrain,]
</code></pre>

<h2>Predicting with Decision Tree</h2>

<p>I will first try decision tree to fit the model.</p>

<p>Cross validation with 5-fold will be used:</p>

<pre><code>control_dt &lt;- trainControl(method="cv", 5)
mod_dt &lt;- train(classe~., data = training_train, method = "rpart",
            trControl = control_dt)

pred_dt &lt;- predict(mod_dt, training_test)
confusionMatrix(pred_dt, training_test$classe)
</code></pre>

<p>Here are the Decision Tree Classification results:</p>

<pre><code>pred_dt &lt;- predict(mod_dt, training_test, type = "class")
confusionMatrix(pred_dt, training_test$classe)

          Reference
Prediction    A    B    C    D    E
         A 1531  483  474  445  145
         B   21  384   36  162  142
         C  118  272  516  357  303
         D    0    0    0    0    0
         E    4    0    0    0  492

Overall Statistics

               Accuracy : 0.4967          
                 95% CI : (0.4838, 0.5095)
    No Information Rate : 0.2845          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

                  Kappa : 0.3419          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9146  0.33714  0.50292   0.0000  0.45471
Specificity            0.6326  0.92394  0.78391   1.0000  0.99917
Pos Pred Value         0.4974  0.51544  0.32950      NaN  0.99194
Neg Pred Value         0.9491  0.85311  0.88192   0.8362  0.89052
Prevalence             0.2845  0.19354  0.17434   0.1638  0.18386
Detection Rate         0.2602  0.06525  0.08768   0.0000  0.08360
Detection Prevalence   0.5230  0.12659  0.26610   0.0000  0.08428
Balanced Accuracy      0.7736  0.63054  0.64342   0.5000  0.72694
</code></pre>

<h2>Predicting with Random Forest</h2>

<p>Second, I will use Random Forest algorithm to fit the model.</p>

<p>Again, cross validation with 5-fold will be used:</p>

<pre><code>control_rf &lt;- trainControl(method = "cv", 5)
mod_rf &lt;- train(classe ~., data = training_train, method = "rf",  
                trControl=control_rf, ntree=250)

pred_rf &lt;- predict(mod_rf, training_test)
confusionMatrix(pred_rf, training_test$classe)
</code></pre>

<p>Here are the Random Forest Classification results:</p>

<pre><code>          Reference
Prediction    A    B    C    D    E
         A 1531  483  474  445  145
         B   21  384   36  162  142
         C  118  272  516  357  303
         D    0    0    0    0    0
         E    4    0    0    0  492

Overall Statistics

               Accuracy : 0.4967          
                 95% CI : (0.4838, 0.5095)
    No Information Rate : 0.2845          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       

                  Kappa : 0.3419          
 Mcnemar's Test P-Value : NA              

Statistics by Class:

                     Class: A Class: B Class: C Class: D Class: E
Sensitivity            0.9146  0.33714  0.50292   0.0000  0.45471
Specificity            0.6326  0.92394  0.78391   1.0000  0.99917
Pos Pred Value         0.4974  0.51544  0.32950      NaN  0.99194
Neg Pred Value         0.9491  0.85311  0.88192   0.8362  0.89052
Prevalence             0.2845  0.19354  0.17434   0.1638  0.18386
Detection Rate         0.2602  0.06525  0.08768   0.0000  0.08360
Detection Prevalence   0.5230  0.12659  0.26610   0.0000  0.08428
Balanced Accuracy      0.7736  0.63054  0.64342   0.5000  0.72694
</code></pre>

<h2>Choosing the Prediction Model and Testing</h2>

<p>Since accuracy for Random Forest model is greater than the accuracy achieved with Decision Tree model, the Random Forests model is choosen for predicting the test data.</p>

<pre><code>

The Results of Final Prediction on Testing Data Set

pred_final &lt;- predict(mod_rf, testing)
pred_final

[1] B A B A A E D B A A B C B A E E A B B B
Levels: A B C D E
</code></pre>
</article>


</body>
</html>
